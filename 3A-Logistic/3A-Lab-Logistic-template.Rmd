---
title: "Lab 3A"
subtitle: "Logistic regression and LDA"
date: "`r format(Sys.time(), '%Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    df_print: paged
    number_sections: false
    theme: paper
    highlight: tango
---


```{r setup, include=F, message=F}
knitr::opts_chunk$set(message=FALSE)

library(MASS)
library(glmnet)
library(caret)
library(ggplot2)
library(dplyr)
library(tidyr)
library(pROC)
```

---





In this lab you train models to classify emails as either spam or non-spam based 57 features of the email. The data set for this lab is `spam` from the package `kernlab`. The variable `type` contains the classifications.

# Data exploration

a. Load the package `kernlab` and load the `spam` in workspace with the function `data()`. Check its help file for the description of the data. 

```{r}

```

b. Display the boxplots of the standardized features (so exclude `type`). What does these plots tell you about the distributions of the features?


```{r}

```

c. To avoid outliers, cut the scores of all 57 features into 4 approximately equal parts. Save the new data set as `spam4`.


```{r}

```


---

# Data partitioning

We first make a vector to partition the data in a training set consisting of 75% of the data, and a test of 25% of the data.

a. Set the seed to 10 for reproducibility, and make the vector `train` consisting of 75% of the row numbers with the function `createDataPartition()`.


```{r}

```

# Model training


We first train the three logistic regression models (one without and two with regularization), and the two  (linear and quadratic) discriminant models.


## Logistic regression

a. Fit the logistic regression model with all 57 features to the training set, and save the object as `train_glm`.

```{r}

```

The warning  `glm.fit: fitted probabilities numerically 0 or 1 occurred` implies that one or more features have extreme parameter estimates and standard errors.

b. Display the parameter estimates and with `coef(summary(train_glm))`, rounded to two decimals, and identify the features with extreme parameters estimates and standard errors.  

```{r}

```

## Lasso and ridge regression

Shrinkage avoids extremely large parameter estimates. The function `glmnet()` performs both lasso   and ridge regression. 

a. Train the logistic regression model with the lasso and the ridge. Do not forget that argument `x` requires a `matrix` as input, and to set the `familiy` to `"binomial"`. Save the objects as `train_lasso` and `train_ridge`.


```{r}

```

b. Plot both objects with the arguments `label = TRUE` and `xvar = "lambda"`. Which coefficients are most affected by the shrinkage. 

```{r}

```


c. Perform a 5-fold cross-validation to determine the optimal value for the shrinkage parameters `lambda` with `cv.glmnet()`. Save the objects as `train_cv.lasso` and `train_cv.ridge`.  

```{r}

```


d. Plot the objects `train_cv.lasso` and `train_cv.lasso`, and interpret the plots. 

```{r}

```

e. Display the parameter estimates of `train_glm`, `spam.cv.lasso` and `spam.cv.ridge` side-by-side with the function `cbind()`, rounded to two decimals.

```{r}

```

## LDA


a. Perform a linear and quadratic discriminant analysis on the `spam4` data. Save the fitted objects under an appropriate name (e.g. `train_lda` and `train_qda`), and display and interpret their content. 

```{r}

```

b. Display and interpret the content of the `lda` and `qda` object. 

```{r}

```

c. Plot the fitted LDA object, and interpret its meaning. 

```{r}

```

# Model testing

It is time to compare the performance of the three logistic models and the two discriminant analyses on the test set.

a. Save the predictions of these models on the test set with the function `predict()`. Check the help files for `predict.glm`, `predict.lda` and `predict.qda` for the arguments. Save the objects under  appropriate names (e.g. `pred_glm`, `pred_lasso`, etc.).


```{r}

```


b. Check the content of the predicted objects, and either compute or extract the factor with the predicted  classifications "nospam" and "spam". Save these factors under appropriate names (e.g. `class_glm`, `class_lasso`, etc.).

```{r}

```


c. Display the confusion matrices of the five models, and save them under appropriate names. 

```{r}

```



d. Compute and display the misclassification test error rates of the five models.


```{r}

```

e. In one figure, display the ROC curves (in different colors) for the test set with the predicted e. In one figure, display and interpret the ROC curves (in different colors) for the predicted probabilities of

    - the random variable `runif(1150)`
    
    - the lasso model 
    
    - the QDA. 

```{r}

```

---

END OF LAB